<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://limyewjin.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://limyewjin.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-22T00:25:55+00:00</updated><id>https://limyewjin.github.io/feed.xml</id><title type="html">Yew Jin</title><subtitle>About Yew Jin. </subtitle><entry><title type="html">AI is reshaping work</title><link href="https://limyewjin.github.io/blog/2025/ai-reshaping-work/" rel="alternate" type="text/html" title="AI is reshaping work"/><published>2025-02-09T08:00:00+00:00</published><updated>2025-02-09T08:00:00+00:00</updated><id>https://limyewjin.github.io/blog/2025/ai-reshaping-work</id><content type="html" xml:base="https://limyewjin.github.io/blog/2025/ai-reshaping-work/"><![CDATA[<p>The rise of Gen AI looking more like AGI is fundamentally changing not just how we work, but how entire careers develop. What happens when this upheaves how we organize and train our workforce?</p> <p>AI isn‚Äôt just automating routine tasks anymore - it‚Äôs taking on complex work in writing, coding, and other knowledge-based fields. But the story isn‚Äôt simple replacement; it‚Äôs transformation.</p> <p>You‚Äôve probably heard that ‚ÄúAI won‚Äôt replace X, but X who use AI will replace those who don‚Äôt.‚Äù This insight seems like at least the immediate trend: Writers who leverage AI for research and first drafts can produce more content faster. Software engineers using AI coding assistants can handle larger projects more efficiently. These professionals aren‚Äôt being replaced - they‚Äôre evolving into hybrid roles where AI amplifies their capabilities.</p> <p>Traditionally, professional careers followed a predictable path: junior employees handled the foundational work, gradually moving up to strategic roles. Junior lawyers reviewed documents before becoming partners. Entry-level software engineers wrote most of the implementation before advancing to system architecture. This apprenticeship model worked well for generations.</p> <p>Now AI is disrupting this progression. When AI can handle many entry-level tasks - from legal research to routine coding - how do newcomers learn the fundamentals? This isn‚Äôt just about job displacement; it‚Äôs about reimagining how we develop expertise.</p> <p>An intriguing model is emerging, drawing parallels to military structure. Just as the military has distinct officer and enlisted tracks, we might see a similar bifurcation in professional careers: humans as strategic leaders and AI as the execution force.</p> <p>In this model, professionals would train from the start as ‚ÄúAI orchestrators‚Äù rather than task executors. Instead of spending years on foundational work, they‚Äôd learn to direct and refine AI outputs, focusing on high-level strategy and quality control. It‚Äôs a significant shift from current professional development, but it might be necessary for the AI era.</p> <h2 id="but-wait-cant-ai-just-take-the-lead">But wait, can‚Äôt AI just take the lead?</h2> <p>The natural question follows: if AI can handle execution, what prevents it from taking over strategy and supervision? The answer lies in distinctly human capabilities (so far) that AI still struggles with:</p> <ul> <li>Complex judgment and common-sense reasoning in novel situations</li> <li>Genuine emotional intelligence and people management</li> <li>Accountability and trust in decision-making</li> <li>Creative vision and value-based strategic thinking</li> </ul> <p>These capabilities keep humans essential in leadership roles, at least for the foreseeable future.</p> <h2 id="what-might-we-do-now-as-humans">What might we do now, as humans?</h2> <ol> <li>Embrace AI as a powerful tool in your toolkit</li> <li>Develop skills that AI can‚Äôt easily replicate - strategic thinking, emotional intelligence, and complex problem-solving</li> <li>Prepare for a more dynamic career path where traditional progression may not apply</li> </ol> <p>The future isn‚Äôt about competing with AI - it‚Äôs about leveraging it effectively while developing uniquely human strengths. The transition presents challenges, but understanding these shifts helps us prepare for and shape the future of work.</p> <p>Success in this new era won‚Äôt come from resisting change, but from adapting to it thoughtfully. The goal is to thrive in it by finding new ways to add value in a very different yet similar workplace.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[How AI is Reshaping Professional Career Paths]]></summary></entry><entry><title type="html">Testing Hoarder and PikaPods</title><link href="https://limyewjin.github.io/blog/2024/hoarder/" rel="alternate" type="text/html" title="Testing Hoarder and PikaPods"/><published>2024-12-26T08:00:00+00:00</published><updated>2024-12-26T08:00:00+00:00</updated><id>https://limyewjin.github.io/blog/2024/hoarder</id><content type="html" xml:base="https://limyewjin.github.io/blog/2024/hoarder/"><![CDATA[<p>I recently started testing <a href="https://github.com/hoarder-app/hoarder">Hoarder</a>, a self-hostable bookmark application that caught my attention with its rich feature set. While there are many bookmark managers out there, Hoarder stands out with some interesting capabilities:</p> <ul> <li> <p>Versatile Content Management: Beyond just saving links, you can take notes and store various types of media like images and PDFs. This flexibility makes it more of a personal knowledge base than just a bookmark manager.</p> </li> <li> <p>Smart Content Processing: It automatically fetches metadata from links, including titles, descriptions, and images. The AI-powered automatic tagging feature (supporting both ChatGPT and local models via Ollama) helps keep your content organized without manual effort.</p> </li> <li> <p>Advanced Search and Organization: With full-text search capabilities and the ability to sort bookmarks into lists, finding and organizing your content is straightforward. The OCR functionality for extracting text from images is particularly useful for making visual content searchable.</p> </li> </ul> <p>I actually prefer <a href="https://github.com/sissbruecker/linkding">Linkding</a> for its cleaner list view, but Hoarder‚Äôs additional features ‚Äì especially the auto-tagging and ability to add notes ‚Äì make it worth the trade-off for my use case.</p> <h2 id="bonus-tip-easy-self-hosting-with-pikapods">Bonus Tip: Easy Self-Hosting with PikaPods</h2> <p>While we‚Äôre on the topic of self-hosting, I wanted to share a fantastic discovery: <a href="https://www.pikapods.com/">PikaPods</a>. As someone who has dealt with the Site Reliability Engineering (SRE) aspects of self-hosting services, I‚Äôve always found it to be a pain point. PikaPods simplifies this entire process ‚Äì you can get your self-hosted services up and running with just a few clicks, eliminating the usual operational headaches. Ok, so it‚Äôs not self-hosting, but for this use-case, I am happy to offload to a service.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Testing a self-hosted bookmark manager (with a pro-tip on how to host it!)]]></summary></entry><entry><title type="html">Quick Prompt Engineering Tip 3 - Grounding LLM Responses</title><link href="https://limyewjin.github.io/blog/2024/llm-tutorial-3/" rel="alternate" type="text/html" title="Quick Prompt Engineering Tip 3 - Grounding LLM Responses"/><published>2024-12-01T08:00:01+00:00</published><updated>2024-12-01T08:00:01+00:00</updated><id>https://limyewjin.github.io/blog/2024/llm-tutorial-3</id><content type="html" xml:base="https://limyewjin.github.io/blog/2024/llm-tutorial-3/"><![CDATA[<p>If we can provide a model with trusted, relevant information, we can guide it to compose answers grounded in that knowledge rather than relying on its training data alone. But how we present this information matters significantly.</p> <p>I recently tested different prompting patterns across Claude, GPT-4, and Gemini where the focus was on two key variables:</p> <ol> <li>Document placement (context before vs. after the question)</li> <li>Quote requirements (explicit vs. implicit)</li> </ol> <p>Key findings from testing across models:</p> <ul> <li>Document-first prompts consistently produced more reliable results - like giving someone a map before asking for directions</li> <li>Quote requests provided an additional safety net against hallucinations, though the impact was smaller than I originally expected</li> <li>Even these ‚Äúsmaller‚Äù models (Haiku, GPT-4o-mini, Gemini 1.5) handled these tasks well, showing how base capabilities have improved</li> </ul> <p>Key takeaways:</p> <ol> <li>When building RAG systems, place your context before questions.</li> <li>When reliability is crucial, add quote requirements as an extra verification layer.</li> </ol> <p>Code and full examples: <a href="https://github.com/limyewjin/llm-tutorial-grounding">https://github.com/limyewjin/llm-tutorial-grounding</a></p>]]></content><author><name></name></author><category term="tutorial"/><category term="llm"/><summary type="html"><![CDATA[Grounding is key, but how should you present the info to LLMs?]]></summary></entry><entry><title type="html">The Mechanical Pencil I Use</title><link href="https://limyewjin.github.io/blog/2024/mechanical-pencils/" rel="alternate" type="text/html" title="The Mechanical Pencil I Use"/><published>2024-12-01T08:00:00+00:00</published><updated>2024-12-01T08:00:00+00:00</updated><id>https://limyewjin.github.io/blog/2024/mechanical-pencils</id><content type="html" xml:base="https://limyewjin.github.io/blog/2024/mechanical-pencils/"><![CDATA[<p>You know that saying about cameras - the best one is the one you have with you? Well, I‚Äôve found the same holds true for mechanical pencils. And after years of frustration with lead-leaking pencils staining my clothes and stabbing me through my pockets, I found my perfect everyday companion a while back and finally got arond to touting it: the <a href="https://www.pentel.com/products/sharp-kerry-mechanical-pencil">Pentel Sharp Kerry</a></p> <p>Let me back up a bit. Like many of us, I‚Äôve had a love-hate relationship with mechanical pencils. While Wirecutter <a href="https://www.nytimes.com/wirecutter/reviews/best-mechanical-pencils/">crowned</a> the Blick Premier as their top pick (and it‚Äôs indeed an excellent pencil), I found my perfect match in their ‚ÄúAlso great‚Äù pick: the Pentel Sharp Kerry. It solves the one problem that matters most to me - it has a cap. Simple, right? But this isn‚Äôt just any cap. The designers at Pentel clearly spent some serious time thinking about how people actually use their pencils.</p> <p>Here‚Äôs what makes it special: you can click the lead even with the cap posted on the back. Sounds minor, but it‚Äôs a game-changer. They even spring-loaded the cap‚Äôs finial (that‚Äôs the fancy word for the end bit) so it doesn‚Äôt rattle around when capped or separated from the pencil. It‚Äôs one of those small details that makes the whole thing feel premium.</p> <p>But my favorite part? The dual-purpose design of the eraser and lead chamber. When you‚Äôre writing with the cap posted on the back, pop off the end finial and you‚Äôve got easy access to the eraser. Not using the pencil? Cap it, and that same removable end reveals the lead chamber for refills. It‚Äôs clever engineering that actually makes sense in daily use.</p> <p>The Kerry isn‚Äôt trying to be the fanciest mechanical pencil out there. Instead, it focuses on being reliable and practical. The 0.5mm lead writes smoothly, and the whole thing feels solid without being heavy. Plus, when you‚Äôre actually writing, you can rotate the pencil to get the sharpest part of the lead on the paper without the pocket clip getting in your way.</p> <p>Is it perfect? Maybe not. But it‚Äôs the first mechanical pencil I‚Äôve actually wanted to carry with me every day. And isn‚Äôt that what really matters? Because just like that camera in your phone, the best mechanical pencil is absolutely the one you‚Äôll actually have with you when you need it.</p> <p>And for me, that‚Äôs the Kerry. No more lead-stained pockets. No more accidentally stabbing myself. Just a reliable writing tool that‚Äôs ready when I am. Sometimes the best solutions are the simplest ones - even if it took a ton of pencil evolution and testing on my part to get there.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[I tried a lot of mechanical pencils; this is the one I use and why]]></summary></entry><entry><title type="html">Quick Prompt Engineering Tip 1 - Chain Your Prompts! üîÑ</title><link href="https://limyewjin.github.io/blog/2024/llm-tutorial-1/" rel="alternate" type="text/html" title="Quick Prompt Engineering Tip 1 - Chain Your Prompts! üîÑ"/><published>2024-11-24T08:00:00+00:00</published><updated>2024-11-24T08:00:00+00:00</updated><id>https://limyewjin.github.io/blog/2024/llm-tutorial-1</id><content type="html" xml:base="https://limyewjin.github.io/blog/2024/llm-tutorial-1/"><![CDATA[<p>The saying goes, ‚ÄúWriting is rewriting.‚Äù The same applies to LLMs! Just like how we ask humans to double-check their work, we can prompt LLMs to review and improve their responses.</p> <p>Here‚Äôs a simple example:</p> <ol> <li>First prompt: ‚ÄúList 10 words ending in ‚Äòab‚Äô‚Äù</li> <li>Chain prompt: ‚ÄúNow check if each word is valid. Show your analysis and replace any invalid ones.‚Äù</li> </ol> <p>This simple chaining technique can lead to improved results. The key is asking the model to:</p> <ul> <li>Show its reasoning</li> <li>Break down its analysis</li> <li>Replace incorrect answers</li> </ul> <p>Important caveat: Like any prompt engineering technique, results vary based on the task complexity and model capability. I tested this with base-tier models across OpenAI, Anthropic, and Google - while the improvement wasn‚Äôt dramatic, the models were able to identify errors from their initial responses without introducing new ones during the chaining step.</p> <p>Always test your prompting strategies! Check out my experiment code here: <a href="https://github.com/limyewjin/llm-tutorial-chaining">https://github.com/limyewjin/llm-tutorial-chaining</a></p>]]></content><author><name></name></author><category term="tutorial"/><category term="llm"/><summary type="html"><![CDATA[The saying goes, 'Writing is rewriting.' The same applies to LLMs!]]></summary></entry><entry><title type="html">Quick Prompt Engineering Tip 2 - Master Length Control in LLMs üìè</title><link href="https://limyewjin.github.io/blog/2024/llm-tutorial-2/" rel="alternate" type="text/html" title="Quick Prompt Engineering Tip 2 - Master Length Control in LLMs üìè"/><published>2024-11-24T08:00:00+00:00</published><updated>2024-11-24T08:00:00+00:00</updated><id>https://limyewjin.github.io/blog/2024/llm-tutorial-2</id><content type="html" xml:base="https://limyewjin.github.io/blog/2024/llm-tutorial-2/"><![CDATA[<p>One common requirement I have using LLMs is controlling their response length (maximum number of words, minimum number of words, number of bullet points, etc.). I have done a few tests to share some key insights for controlling length in LLMs.</p> <h1 id="response-text-length">Response Text Length</h1> <ul> <li>‚ÄúAt Most X Words‚Äù What surprised me most was how consistently the ‚Äúat most X words‚Äù format outperformed other approaches. While exact word counts tend to overshoot by 10-15%, the ‚Äúat most‚Äù modifier acts like a reliable ceiling. In our tests, the various models from Anthropic, Google, and OpenAI consistently stayed under the specified limit.</li> </ul> <p>A Practical Framework for Length Control:</p> <ol> <li>For Strict Upper Bounds: Use ‚Äúat most X words‚Äù - it‚Äôs your most reliable tool across all models. I‚Äôve found this especially crucial for applications with strict space constraints.</li> <li>For Minimum Length Requirements: The ‚Äúat least X words‚Äù modifier works, but expect significant variations. In our tests, outputs ranged from 119 to 238 words for a 100-word minimum requirement. If you need longer content, this is actually a feature, not a bug.</li> <li>Avoid Common Pitfalls:</li> </ol> <ul> <li>Qualitative descriptors (‚Äúshort,‚Äù ‚Äúvery short‚Äù) showed the highest variance in our tests</li> <li>Reading time estimates (‚Äú30 seconds long‚Äù) proved surprisingly inconsistent</li> <li>The format of numbers (‚Äú100‚Äù vs ‚Äúone hundred‚Äù) doesn‚Äôt significantly impact results</li> </ul> <h1 id="bullet-points">Bullet Points</h1> <p>As you might expect, using ordered lists (e.g., 1., 2., 3., ‚Ä¶) works better than unordered, but really only for longer lists. The models across Anthropic, Google, and OpenAI show near-perfect precision for small to medium lists (3-20 points) but diverge significantly with larger requests. For instance, when asking for 50 points, OpenAI tends to overshoot while Anthropic often undershoots with ordered lists.</p> <p>What‚Äôs been your experience with controlling LLM output length? Have you noticed any patterns I might have missed in my testing? Let‚Äôs continue building our collective understanding of these fascinating tools.</p> <p>Code &amp; data here: <a href="https://github.com/limyewjin/llm-tutorial-length">https://github.com/limyewjin/llm-tutorial-length</a></p>]]></content><author><name></name></author><category term="tutorial"/><category term="llm"/><summary type="html"><![CDATA[One common requirement I have using LLMs is controlling their response length]]></summary></entry><entry><title type="html">What‚Äôs Next?</title><link href="https://limyewjin.github.io/blog/2024/bullshit-ai-jobs/" rel="alternate" type="text/html" title="What‚Äôs Next?"/><published>2024-08-03T08:00:00+00:00</published><updated>2024-08-03T08:00:00+00:00</updated><id>https://limyewjin.github.io/blog/2024/bullshit-ai-jobs</id><content type="html" xml:base="https://limyewjin.github.io/blog/2024/bullshit-ai-jobs/"><![CDATA[<p>John Maynard Keynes predicted a 15-hour workweek, but we‚Äôve instead created millions of pointless jobs. It‚Äôs like how we have 100x more powerful machines and storage, yet our calculator apps have bloated to use 99x of that improvement.</p> <p>In 2013, anthropologist David Graeber coined the term ‚Äòbullshit jobs‚Äô - roles so meaningless that even those doing them struggle to justify their existence. Fast forward to 2024, and AI is poised to automate many of these jobs.</p> <p>As AI threatens to displace 300 million full-time jobs globally, we‚Äôre at a crossroads. Could AI finally deliver on Keynes‚Äô vision by eliminating ‚Äòbullshit jobs‚Äô? Or will it simply create new forms of meaningless work, like ‚ÄòAI babysitters‚Äô?</p> <p>I‚Äôm a tech optimist, but an incentive pessimist. People make money doing jobs, even if they‚Äôre meaningless. So I predict a Cambrian explosion of bullshit AI jobs. What do you think?</p>]]></content><author><name></name></author><summary type="html"><![CDATA[I hope I'm wrong on this one...]]></summary></entry><entry><title type="html">What‚Äôs Next?</title><link href="https://limyewjin.github.io/blog/2024/what-next/" rel="alternate" type="text/html" title="What‚Äôs Next?"/><published>2024-07-10T08:00:00+00:00</published><updated>2024-07-10T08:00:00+00:00</updated><id>https://limyewjin.github.io/blog/2024/what-next</id><content type="html" xml:base="https://limyewjin.github.io/blog/2024/what-next/"><![CDATA[<p>Just read ‚ÄúDefeated by A.I., a Legend in the Board Game Go Warns: Get Ready for What‚Äôs Next‚Äù<sup id="fnref:0" role="doc-noteref"><a href="#fn:0" class="footnote" rel="footnote">1</a></sup>, and as someone who did their PhD in game-tree search, I‚Äôve watched in awe as AI has evolved from mastering board games to tackling some of humanity‚Äôs most pressing challenges. The journey from early game-playing algorithms to today‚Äôs multifaceted AI systems is nothing short of extraordinary.</p> <h3 id="the-game-changing-progression">The Game-Changing Progression</h3> <p>The evolution of game AI tells a fascinating story of human ingenuity. We started with simple minimax algorithms and alpha-beta pruning, techniques that seemed cutting-edge at the time. Then came knowledge-based systems, leveraging human expertise to improve performance.</p> <p>A significant leap during my PhD was the advent of Monte Carlo methods, particularly Monte Carlo Tree Search (MCTS). This probabilistic approach opened new horizons, allowing AI to handle the vast complexity of games like Go.</p> <p>In fact, the impact of MCTS on the field was so profound that it accelerated my own academic journey. I was deep into my PhD research on forward pruning and selective search in game-tree search when MCTS emerged. It quickly became clear that complete game-tree search might not be the future of game AI. This realization prompted me to swiftly wrap up my research into a PhD thesis. The last paragraph of my PhD thesis reflects this pivotal moment:</p> <blockquote> <p>The game of Go can be considered as the grand challenge of game AI at this point in time. One interesting development in computer Go has been the introduction of Monte Carlo methods that combine game-tree search and randomly generated moves for evaluation [Coulom, 2006, Kocsis and Szepesv√°ri, 2006]. The random nature of Monte Carlo methods corresponds well with the theoretical analysis of the properties of forward pruning presented in this thesis, and should extend to Monte Carlo tree search. More research on how to incorporate risk management strategies in forward pruning can be done to further improve the state of the art for Monte Carlo tree search.‚Äù</p> </blockquote> <p>Looking back, it‚Äôs remarkable how accurate this assessment was. MCTS indeed became a cornerstone in advanced game AI, particularly in conquering the game of Go.</p> <p>But the true revolution came with the integration of deep learning. Neural networks, once considered a relic of AI‚Äôs past, roared back to life. They brought with them the ability to learn complex patterns and strategies from raw data. This culminated in the creation of AlphaGo, a system that shocked the world by defeating Lee Saedol, one of the greatest Go players of our time.</p> <p>Yet, AlphaGo was just the beginning. AlphaGo Zero and then AlphaZero demonstrated that AI could learn superhuman strategies without any human knowledge, purely through self-play. The implications were staggering.</p> <h3 id="beyond-the-game-board">Beyond the Game Board</h3> <p>What truly excites me is how these game-playing techniques have found applications far beyond the world of board games. Let me share some cutting-edge examples:</p> <h4 id="weather-forecasting">Weather Forecasting</h4> <p>The advancements in game AI have found significant applications beyond the game board, one of which is weather forecasting. Google‚Äôs MetNet-3<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">2</a></sup> leverages techniques reminiscent of those used in game AI to tackle the complexities of atmospheric dynamics. By integrating the data assimilation and simulation processes into a single neural network pass, MetNet-3 can provide high-resolution weather predictions up to 24 hours ahead, covering variables such as precipitation, temperature, wind, and dew point. This model outperforms traditional physics-based numerical weather prediction methods, achieving temporal resolutions as fine as two minutes and spatial resolutions of one to four kilometers.</p> <h4 id="drug-discovery">Drug Discovery</h4> <p>In the realm of drug discovery, AI techniques refined in game-playing applications are accelerating research and development. Insilico Medicine‚Äôs AI-generated drug for idiopathic pulmonary fibrosis (IPF) is a prime example. Their AI system, which includes platforms like PandaOmics and Chemistry42, identified a novel therapeutic target (TNIK) and designed a small molecule (INS018_055) for IPF treatment in just 18 months, a process that traditionally takes years. This AI-driven approach mirrors game AI‚Äôs method of identifying key strategic points and developing optimal strategies to exploit them. The rapid progression of this AI-designed drug, now in Phase 2 clinical trials, underscores the potential of AI in pharmaceutical research.</p> <h4 id="molecular-biology">Molecular Biology</h4> <p>In molecular biology, the impact of AI is profoundly illustrated by AlphaFold 3<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">3</a></sup>, which extends the capabilities of its predecessor by predicting the structure and interactions of a wide range of biological molecules, including proteins, DNA, RNA, and small molecules. This progression from predicting protein structures to modeling complex molecular interactions showcases the significant leap in AI‚Äôs application in biology. AlphaFold 3‚Äôs enhanced architecture, featuring an improved Evoformer module and a diffusion network, has achieved a substantial improvement in the accuracy of predicting protein interactions, further advancing our understanding of cellular biology.</p> <h3 id="the-common-thread">The Common Thread</h3> <p>What fascinates me most is the common thread running through all these applications ‚Äì the ability of AI to learn complex patterns and make decisions in high-dimensional, uncertain environments. Whether it‚Äôs navigating the vast possibility space of Go, predicting chaotic weather systems, or exploring the intricate world of molecular structures, AI is proving to be a powerful tool.</p> <h3 id="looking-ahead">Looking Ahead</h3> <p>As we stand at this exciting juncture, I can‚Äôt help but wonder: what‚Äôs next? Which field will see the next AlphaZero-like breakthrough? How might these AI techniques reshape your industry?</p> <p>One thing is certain ‚Äì we‚Äôre not just spectators in this AI renaissance. We‚Äôre potential collaborators, innovators, and pioneers. The games AI has learned to play have prepared it for the greatest game of all ‚Äì advancing human knowledge and capabilities across all fields of endeavor.</p> <p>I‚Äôm eager to hear your thoughts. How do you see AI impacting your field in the coming years?</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:0" role="doc-endnote"> <p><a href="https://www.nytimes.com/2024/07/10/world/asia/lee-saedol-go-ai.html">NYTimes - Defeated by A.I., a Legend in the Board Game Go Warns: Get Ready for What‚Äôs Next</a>¬†<a href="#fnref:0" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:1" role="doc-endnote"> <p><a href="https://research.google/blog/metnet-3-a-state-of-the-art-neural-weather-model-available-in-google-products/">Google Research - MetNet-3</a>¬†<a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2" role="doc-endnote"> <p><a href="https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/#future-cell-biology">Google Blog - AlphaFold 3</a>¬†<a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="showerthoughts"/><summary type="html"><![CDATA[Let me get my popcorn...]]></summary></entry><entry><title type="html">Breaking down silos to grow</title><link href="https://limyewjin.github.io/blog/2024/breaking-silos/" rel="alternate" type="text/html" title="Breaking down silos to grow"/><published>2024-04-03T08:00:00+00:00</published><updated>2024-04-03T08:00:00+00:00</updated><id>https://limyewjin.github.io/blog/2024/breaking-silos</id><content type="html" xml:base="https://limyewjin.github.io/blog/2024/breaking-silos/"><![CDATA[<p>Here‚Äôs the thing: growth ideas often come from thinking outside the box and looking at the full complexity of the user flow, rather than getting stuck in the silos created by products, features, and org structures.</p> <p>Basically, no matter how you slice and dice your projects to optimize for Growth (capital G), the real growth (lowercase g) often lies in the seams between those projects and teams.</p> <p>Picture this: a widget company has a deals team that busts their posteriors to secure awesome Black Friday discounts. They even get those deals featured on the homepage. Sounds great, right? All those users flooding the site will see the deals and go wild!</p> <p>But wait, what about the email and notifications team? Shouldn‚Äôt they be crafting personalized updates and maybe even more exclusive deals for engaged users? And what about marketing? Are they on the same page with messaging, or will users get confused by mixed signals?</p> <p>In big companies, this kind of coordination doesn‚Äôt happen automagically. Teams often optimize for their own little fiefdoms without seeing the bigger picture.</p> <p>Now, decentralizing growth efforts is usually the secret to scaling. Trying to centralize everything just creates org friction and slows things down.</p> <p>But there are times when it‚Äôs worth the extra elbow grease to get everyone singing from the same hymnal. My rule of thumb? When there‚Äôs a tidal wave of users expected, like during Black Friday or the World Cup, it‚Äôs time to yell (figuratively!) and get all hands on deck.</p> <p>At the end of the day, growth is a team sport. By breaking down silos and looking at the big picture, you can find those hidden gems that really move the needle.</p>]]></content><author><name></name></author><category term="growth"/><summary type="html"><![CDATA[Doing growth is like finding coins between the couch cushions]]></summary></entry><entry><title type="html">For growth‚Äôs sake, don‚Äôt be dogmatic</title><link href="https://limyewjin.github.io/blog/2024/do-not-dogmatic/" rel="alternate" type="text/html" title="For growth‚Äôs sake, don‚Äôt be dogmatic"/><published>2024-03-24T08:00:00+00:00</published><updated>2024-03-24T08:00:00+00:00</updated><id>https://limyewjin.github.io/blog/2024/do-not-dogmatic</id><content type="html" xml:base="https://limyewjin.github.io/blog/2024/do-not-dogmatic/"><![CDATA[<p>I am reading <a href="https://g.co/kgs/mVUfke">Build: An Unorthodox Guide to Making Things Worth Making Book</a> by Tony Fadell -</p> <p>I wanted to call out Tony‚Äôs description on how to make a big change:</p> <blockquote> <p>A company that‚Äôs likely to make a substantial change in the status quo has the following characteristics:</p> <ol> <li>It‚Äôs creating a product or service that‚Äôs wholly new or combines existing technology in a novel way that the competition can‚Äôt make or even understand.</li> <li>This product solves a problem‚Äîa real pain point-that a lot of customers experience daily. There should be an existing large market.</li> <li>The novel technology can deliver on the company vision-not just within the product but also the infrastructure, platforms, and systems that support it.</li> </ol> <p><em>4. Leadership is not dogmatic about what the solution looks like and is willing to adapt to their customers‚Äô needs</em>.</p> <ol> <li>It‚Äôs thinking about a problem or a customer need in a way you‚Äôve never heard before, but which makes perfect sense once you hear it.</li> </ol> </blockquote> <p>I especially like the fourth point about not being dogmatic. This point is crucial because it emphasizes the importance of being humble and adaptable in the face of real-world feedback. As the Mike Tyson famously once said, ‚ÄúEveryone has a plan until they get punched in the face.‚Äù In my team I like to say: ‚ÄúEveryone has a Growth plan until they run their first live experiment.‚Äù</p> <p>It‚Äôs easy to fall in love with our own product vision and believe that we know exactly what our users need. However, the reality is that our assumptions are often wrong or incomplete. Only by putting our products in front of real users and gathering feedback can we truly understand what works and what doesn‚Äôt.</p> <p>Be humble. This doesn‚Äôt mean abandoning our vision altogether, but rather being open to tweaking and refining it based on real-world insights. The most successful products are those that strike a balance between a strong vision and a willingness to iterate based on user feedback. This requires a leadership team that is confident enough to set a direction, but humble enough to admit when they need to course-correct (and knowing when to do so quickly!)</p>]]></content><author><name></name></author><category term="growth"/><summary type="html"><![CDATA[I prefer live experiments over getting punched in the face]]></summary></entry></feed>